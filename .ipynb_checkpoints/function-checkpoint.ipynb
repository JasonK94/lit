{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ed66d0f-2851-4ce7-b49f-8d4c624cbbbf",
   "metadata": {},
   "source": [
    "# pre-process xenium data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "affcc286-6e01-40e2-8da2-6b08ef3ffe6d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_spatial_data(adata_path, output_dir, output_prefix, n_pcs, n_neighbors, leiden_res):\n",
    "    # (이전 답변의 preprocess_spatial_data 함수 내용과 동일)\n",
    "    print(f\"--- Starting Spatial Data Preprocessing: {adata_path} ---\")\n",
    "    try:\n",
    "        adata = sc.read_h5ad(adata_path)\n",
    "        print(f\"Loaded spatial data: {adata}\")\n",
    "\n",
    "        # QC, Filtering, Normalization, Log, HVG, Scale, PCA, Neighbors, Leiden, UMAP\n",
    "        sc.pp.calculate_qc_metrics(adata, percent_top=None, log1p=False, inplace=True)\n",
    "        min_genes = 20; min_counts = 50; min_cells = 5\n",
    "        print(f\"Cells before filtering: {adata.n_obs}\")\n",
    "        sc.pp.filter_cells(adata, min_genes=min_genes)\n",
    "        sc.pp.filter_cells(adata, min_counts=min_counts)\n",
    "        print(f\"Genes before filtering: {adata.n_vars}\")\n",
    "        sc.pp.filter_genes(adata, min_cells=min_cells)\n",
    "        print(f\"Data shape after filtering: {adata.shape}\")\n",
    "        if adata.n_obs == 0 or adata.n_vars == 0:\n",
    "             raise ValueError(\"Data is empty after filtering.\")\n",
    "\n",
    "        sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "        sc.pp.log1p(adata)\n",
    "        sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, flavor='seurat_v3')\n",
    "        n_hvg = adata.var['highly_variable'].sum()\n",
    "        print(f\"Found {n_hvg} highly variable genes.\")\n",
    "        if n_hvg == 0:\n",
    "            print(\"No highly variable genes found. Using all genes for PCA.\")\n",
    "            adata.var['highly_variable'] = True # Use all if none found\n",
    "\n",
    "        sc.pp.scale(adata, max_value=10)\n",
    "        sc.tl.pca(adata, svd_solver='arpack', use_highly_variable=True)\n",
    "        # Ensure enough PCs were computed\n",
    "        actual_n_pcs = min(n_pcs, adata.obsm['X_pca'].shape[1])\n",
    "        if actual_n_pcs < n_pcs:\n",
    "             print(f\"Requested {n_pcs} PCs, but only {actual_n_pcs} could be computed.\")\n",
    "        if actual_n_pcs == 0:\n",
    "             raise ValueError(\"PCA could not be computed.\")\n",
    "\n",
    "        sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=actual_n_pcs)\n",
    "        sc.tl.leiden(adata, resolution=leiden_res, key_added=f'leiden_res{leiden_res}')\n",
    "        sc.tl.umap(adata)\n",
    "\n",
    "        print(\"Spatial data preprocessing complete.\")\n",
    "        print(f\"Final spatial AnnData object after preprocessing: {adata}\")\n",
    "        # Optional: Save UMAP plot\n",
    "        # sc.pl.umap(adata, color=[f'leiden_res{leiden_res}'], save=f\"_{output_prefix}_st_umap_leiden_{datetime.now.strftime(\"%y-%m-%d-%H-%M\")}.png\", show=False, title=f'Leiden Clusters (res={leiden_res})')\n",
    "        return adata\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during spatial data preprocessing: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd873e6d-12b9-4cb2-8ffc-9984aa9ab4b2",
   "metadata": {},
   "source": [
    "# 약간 변경: dir를 받는 게 아니라 객체를 그대로 받도록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c7546ef-b8c7-487d-aeb8-254817235641",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_ann_data(adata, output_dir, output_prefix, n_pcs, n_neighbors, leiden_res):\n",
    "    \n",
    "    print(f\"--- Starting Ann Data(read from sc.read_h5ad) Preprocessing ---\")\n",
    "    try:\n",
    "        print(f\"Loaded spatial data: {adata}\")\n",
    "\n",
    "        # QC, Filtering, Normalization, Log, HVG, Scale, PCA, Neighbors, Leiden, UMAP\n",
    "        sc.pp.calculate_qc_metrics(adata, percent_top=None, log1p=False, inplace=True)\n",
    "        min_genes = 20; min_counts = 50; min_cells = 5\n",
    "        print(f\"Cells before filtering: {adata.n_obs}\")\n",
    "        sc.pp.filter_cells(adata, min_genes=min_genes)\n",
    "        sc.pp.filter_cells(adata, min_counts=min_counts)\n",
    "        print(f\"Genes before filtering: {adata.n_vars}\")\n",
    "        sc.pp.filter_genes(adata, min_cells=min_cells)\n",
    "        print(f\"Data shape after filtering: {adata.shape}\")\n",
    "        if adata.n_obs == 0 or adata.n_vars == 0:\n",
    "             raise ValueError(\"Data is empty after filtering.\")\n",
    "\n",
    "        sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "        sc.pp.log1p(adata)\n",
    "        sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, flavor='seurat_v5')\n",
    "        n_hvg = adata.var['highly_variable'].sum()\n",
    "        print(f\"Found {n_hvg} highly variable genes.\")\n",
    "        if n_hvg == 0:\n",
    "            print(\"No highly variable genes found. Using all genes for PCA.\")\n",
    "            adata.var['highly_variable'] = True # Use all if none found\n",
    "\n",
    "        sc.pp.scale(adata, max_value=10)\n",
    "        sc.tl.pca(adata, svd_solver='arpack', use_highly_variable=True)\n",
    "        # Ensure enough PCs were computed\n",
    "        actual_n_pcs = min(n_pcs, adata.obsm['X_pca'].shape[1])\n",
    "        if actual_n_pcs < n_pcs:\n",
    "             print(f\"Requested {n_pcs} PCs, but only {actual_n_pcs} could be computed.\")\n",
    "        if actual_n_pcs == 0:\n",
    "             raise ValueError(\"PCA could not be computed.\")\n",
    "\n",
    "        sc.pp.neighbors(adata, n_neighbors=n_neighbors, n_pcs=actual_n_pcs)\n",
    "        sc.tl.leiden(adata, resolution=leiden_res, key_added=f'leiden_res{leiden_res}')\n",
    "        sc.tl.umap(adata)\n",
    "\n",
    "        print(\"Spatial data preprocessing complete.\")\n",
    "        print(f\"Final spatial AnnData object after preprocessing: {adata}\")\n",
    "        # Optional: Save UMAP plot\n",
    "        # sc.pl.umap(adata, color=[f'leiden_res{leiden_res}'], save=f\"_{output_prefix}_st_umap_leiden.png\", show=False, title=f'Leiden Clusters (res={leiden_res})')\n",
    "        return adata\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during spatial data preprocessing: {e}\", exc_info=True)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7615b370-40cf-42ea-97d4-2c58e3f532c2",
   "metadata": {},
   "source": [
    "# 여러 파라미터도 받을 수 있도록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64327dfe-4055-4839-9036-1f64d4e452d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "from typing import Optional, Literal\n",
    "\n",
    "def preprocess_ann_data_flexible(\n",
    "    adata: ad.AnnData,\n",
    "    output_dir: str, # 필요시 사용 (예: plot 저장)\n",
    "    output_prefix: str, # 필요시 사용 (예: plot 저장)\n",
    "    # QC Parameters\n",
    "    min_genes: int = 20,\n",
    "    min_counts: int = 50,\n",
    "    min_cells: int = 5,\n",
    "    # Normalization Parameters\n",
    "    normalization_method: Optional[Literal['log_normalize']] = 'log_normalize', # 'log_normalize' 또는 None\n",
    "    target_sum: Optional[float] = 1e4, # log_normalize 시 사용\n",
    "    # HVG Parameters (기존 로직 유지, 필요시 추가 파라미터화 가능)\n",
    "    hvg_min_mean: float = 0.0125,\n",
    "    hvg_max_mean: float = 3,\n",
    "    hvg_min_disp: float = 0.5,\n",
    "    hvg_flavor: str = 'seurat_v5',\n",
    "    # Dimensionality Reduction Parameters\n",
    "    n_pcs: int = 50,\n",
    "    # Neighbor Graph Parameters\n",
    "    n_neighbors: int = 15,\n",
    "    # Clustering Parameters\n",
    "    clustering_method: Literal['leiden', 'louvain'] = 'leiden',\n",
    "    cluster_resolution: float = 1.0,\n",
    "    cluster_key_added: Optional[str] = None # None이면 자동으로 생성\n",
    ") -> ad.AnnData:\n",
    "    \"\"\"\n",
    "    AnnData 객체를 전처리하는 함수. QC, 필터링, 정규화, HVG선별, 스케일링,\n",
    "    PCA, Neighbors 계산, 클러스터링(Leiden 또는 Louvain), UMAP 계산을 수행합니다.\n",
    "\n",
    "    Args:\n",
    "        adata: 입력 AnnData 객체.\n",
    "        output_dir: 출력 디렉토리 경로 (현재 함수 내에서는 직접 사용되지 않음).\n",
    "        output_prefix: 출력 파일 접두사 (현재 함수 내에서는 직접 사용되지 않음).\n",
    "        min_genes: 세포 필터링 시 최소 유전자 수.\n",
    "        min_counts: 세포 필터링 시 최소 count 수.\n",
    "        min_cells: 유전자 필터링 시 최소 세포 수.\n",
    "        normalization_method: 정규화 방법. 'log_normalize' 또는 None.\n",
    "        target_sum: 'log_normalize' 시 사용할 target sum.\n",
    "        hvg_min_mean, hvg_max_mean, hvg_min_disp, hvg_flavor: highly_variable_genes 파라미터.\n",
    "        n_pcs: PCA 계산 시 사용할 주성분 개수.\n",
    "        n_neighbors: Neighbors 계산 시 사용할 이웃 수.\n",
    "        clustering_method: 사용할 클러스터링 알고리즘 ('leiden' 또는 'louvain').\n",
    "        cluster_resolution: 클러스터링 해상도.\n",
    "        cluster_key_added: 클러스터링 결과를 저장할 obs 키 이름. None이면 자동 생성.\n",
    "\n",
    "    Returns:\n",
    "        전처리된 AnnData 객체.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: 필터링 후 데이터가 비어 있거나 PCA 계산이 불가능한 경우.\n",
    "        Exception: 기타 전처리 오류 발생 시.\n",
    "    \"\"\"\n",
    "    print(f\"--- Starting AnnData Preprocessing ---\")\n",
    "    try:\n",
    "        print(f\"Input AnnData: {adata}\")\n",
    "        adata_processed = adata.copy() # 원본 보존을 위해 복사본 사용\n",
    "\n",
    "        # 1. QC 및 필터링\n",
    "        print(\"Calculating QC metrics...\")\n",
    "        sc.pp.calculate_qc_metrics(adata_processed, percent_top=None, log1p=False, inplace=True)\n",
    "\n",
    "        print(f\"Filtering cells (min_genes={min_genes}, min_counts={min_counts})...\")\n",
    "        print(f\"Cells before filtering: {adata_processed.n_obs}\")\n",
    "        sc.pp.filter_cells(adata_processed, min_genes=min_genes)\n",
    "        sc.pp.filter_cells(adata_processed, min_counts=min_counts)\n",
    "        print(f\"Cells after filtering: {adata_processed.n_obs}\")\n",
    "\n",
    "        print(f\"Filtering genes (min_cells={min_cells})...\")\n",
    "        print(f\"Genes before filtering: {adata_processed.n_vars}\")\n",
    "        sc.pp.filter_genes(adata_processed, min_cells=min_cells)\n",
    "        print(f\"Genes after filtering: {adata_processed.n_vars}\")\n",
    "\n",
    "        print(f\"Data shape after filtering: {adata_processed.shape}\")\n",
    "        if adata_processed.n_obs == 0 or adata_processed.n_vars == 0:\n",
    "            raise ValueError(\"Data is empty after filtering.\")\n",
    "\n",
    "        # 2. 정규화\n",
    "        if normalization_method == 'log_normalize':\n",
    "            print(f\"Applying log-normalization (target_sum={target_sum})...\")\n",
    "            sc.pp.normalize_total(adata_processed, target_sum=target_sum)\n",
    "            sc.pp.log1p(adata_processed)\n",
    "        elif normalization_method is None:\n",
    "            print(\"Skipping normalization.\")\n",
    "        else:\n",
    "            print(f\"Warning: Unknown normalization method '{normalization_method}'. Skipping.\")\n",
    "\n",
    "        # 3. Highly Variable Genes (HVG)\n",
    "        print(\"Finding highly variable genes...\")\n",
    "        sc.pp.highly_variable_genes(\n",
    "            adata_processed,\n",
    "            min_mean=hvg_min_mean,\n",
    "            max_mean=hvg_max_mean,\n",
    "            min_disp=hvg_min_disp,\n",
    "            flavor=hvg_flavor\n",
    "        )\n",
    "        n_hvg = adata_processed.var['highly_variable'].sum()\n",
    "        print(f\"Found {n_hvg} highly variable genes.\")\n",
    "        if n_hvg == 0:\n",
    "            print(\"Warning: No highly variable genes found. Using all genes for downstream analysis.\")\n",
    "            # 모든 유전자를 사용하도록 설정 (PCA 등에서 use_highly_variable=False 사용 필요)\n",
    "            use_hvg = False\n",
    "        else:\n",
    "            use_hvg = True # HVG를 사용하는 것이 기본\n",
    "\n",
    "        # 4. 스케일링 (HVG 기반 또는 전체 유전자 기반)\n",
    "        print(\"Scaling data...\")\n",
    "        # 스케일링은 보통 HVG에 대해서만 수행하거나, 모든 유전자에 대해 수행 후 HVG 정보는 유지합니다.\n",
    "        # 여기서는 모든 유전자를 스케일링하고, PCA에서 HVG 사용 여부를 결정합니다.\n",
    "        sc.pp.scale(adata_processed, max_value=10)\n",
    "\n",
    "        # 5. PCA (차원 축소)\n",
    "        print(\"Running PCA...\")\n",
    "        # 만약 HVG가 없다면 모든 유전자를 사용합니다.\n",
    "        sc.tl.pca(adata_processed, svd_solver='arpack', use_highly_variable=use_hvg, n_comps=min(n_pcs * 2, adata_processed.n_vars - 1, adata_processed.n_obs - 1)) # 충분한 컴포넌트 계산\n",
    "\n",
    "        # 실제 사용될 PC 개수 확인 및 조정\n",
    "        if 'X_pca' not in adata_processed.obsm:\n",
    "             raise ValueError(\"PCA could not be computed.\")\n",
    "        actual_n_pcs = min(n_pcs, adata_processed.obsm['X_pca'].shape[1])\n",
    "        if actual_n_pcs < n_pcs:\n",
    "            print(f\"Requested {n_pcs} PCs, but only {actual_n_pcs} could be computed.\")\n",
    "        if actual_n_pcs == 0:\n",
    "            raise ValueError(\"PCA resulted in 0 components.\")\n",
    "        # 사용하지 않을 PCA 컴포넌트 제거 (메모리 관리)\n",
    "        if adata_processed.obsm['X_pca'].shape[1] > actual_n_pcs:\n",
    "             adata_processed.obsm['X_pca'] = adata_processed.obsm['X_pca'][:, :actual_n_pcs]\n",
    "             adata_processed.uns['pca']['variance'] = adata_processed.uns['pca']['variance'][:actual_n_pcs]\n",
    "             adata_processed.uns['pca']['variance_ratio'] = adata_processed.uns['pca']['variance_ratio'][:actual_n_pcs]\n",
    "             adata_processed.varm['PCs'] = adata_processed.varm['PCs'][:, :actual_n_pcs]\n",
    "\n",
    "\n",
    "        # 6. Neighbors Graph\n",
    "        print(\"Calculating neighbors graph...\")\n",
    "        sc.pp.neighbors(adata_processed, n_neighbors=n_neighbors, n_pcs=actual_n_pcs)\n",
    "\n",
    "        # 7. 클러스터링\n",
    "        print(f\"Running {clustering_method} clustering (resolution={cluster_resolution})...\")\n",
    "        # 클러스터링 결과 저장 키 설정\n",
    "        if cluster_key_added is None:\n",
    "            cluster_key_added = f\"{clustering_method}_res{cluster_resolution}\"\n",
    "\n",
    "        if clustering_method == 'leiden':\n",
    "            sc.tl.leiden(adata_processed, resolution=cluster_resolution, key_added=cluster_key_added)\n",
    "        elif clustering_method == 'louvain':\n",
    "            sc.tl.louvain(adata_processed, resolution=cluster_resolution, key_added=cluster_key_added)\n",
    "        else:\n",
    "            print(f\"Warning: Unknown clustering method '{clustering_method}'. Skipping clustering.\")\n",
    "\n",
    "        # 8. UMAP (시각화)\n",
    "        print(\"Running UMAP...\")\n",
    "        sc.tl.umap(adata_processed)\n",
    "\n",
    "        print(\"--- AnnData Preprocessing Complete ---\")\n",
    "        print(f\"Final AnnData object after preprocessing: {adata_processed}\")\n",
    "\n",
    "        # 예시: UMAP 플롯 저장 (필요시 주석 해제)\n",
    "        # if clustering_method in ['leiden', 'louvain']:\n",
    "        #     fig_path = os.path.join(output_dir, f\"{output_prefix}_umap_{cluster_key_added}.png\")\n",
    "        #     sc.pl.umap(adata_processed, color=[cluster_key_added], save=fig_path, show=False, title=f'{clustering_method.capitalize()} Clusters (res={cluster_resolution})')\n",
    "        #     print(f\"UMAP plot saved to {fig_path}\")\n",
    "\n",
    "        return adata_processed\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during data preprocessing: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc() # 상세 에러 로그 출력\n",
    "        raise # 에러를 다시 발생시켜 호출자가 알 수 있도록 함\n",
    "\n",
    "# --- 예시 사용법 ---\n",
    "# import scanpy as sc\n",
    "# # 가상의 AnnData 객체 생성 또는 로드\n",
    "# # adata = sc.read_h5ad(\"your_data.h5ad\")\n",
    "# adata = sc.datasets.pbmc3k_processed() # 예시 데이터셋 (이미 일부 전처리됨)\n",
    "# adata = adata[:500, :1000].copy() # 작은 예시 데이터\n",
    "# adata.X = adata.X.astype(float) # 타입 확인\n",
    "\n",
    "# # 함수 호출\n",
    "# processed_adata = preprocess_ann_data_flexible(\n",
    "#     adata=adata,\n",
    "#     output_dir='./results',\n",
    "#     output_prefix='pbmc_processed',\n",
    "#     min_genes=50,\n",
    "#     min_counts=100,\n",
    "#     min_cells=3,\n",
    "#     normalization_method='log_normalize',\n",
    "#     target_sum=1e4,\n",
    "#     n_pcs=30,\n",
    "#     n_neighbors=10,\n",
    "#     clustering_method='louvain', # louvain 사용\n",
    "#     cluster_resolution=0.5\n",
    "# )\n",
    "# print(\"\\nProcessed AnnData info:\")\n",
    "# print(processed_adata)\n",
    "# if 'louvain_res0.5' in processed_adata.obs.columns:\n",
    "#     print(\"\\nLouvain clusters:\")\n",
    "#     print(processed_adata.obs['louvain_res0.5'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce91c01a-abee-46ac-b23a-bf677d2ecd44",
   "metadata": {},
   "source": [
    "# integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f52b8b-7529-4b4d-a85d-d47e83ad867c",
   "metadata": {},
   "source": [
    "## first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "effd58ad-7274-48dd-bca5-9cb6a71a8db9",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 'harmonypy' not found. Harmony integration will not be available. Install with 'pip install harmonypy'\n",
      "Using scvi-tools version: 1.3.0\n",
      "Warning: 'scanorama' not found. Scanorama integration will not be available. Install with 'pip install scanorama'\n"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "from typing import List, Literal, Optional, Dict, Any\n",
    "import os\n",
    "\n",
    "# 필요한 외부 라이브러리 import 시도 (오류 발생 시 사용자에게 설치 안내)\n",
    "try:\n",
    "    import harmonypy\n",
    "except ImportError:\n",
    "    print(\"Warning: 'harmonypy' not found. Harmony integration will not be available. Install with 'pip install harmonypy'\")\n",
    "try:\n",
    "    import scvi\n",
    "    # scvi-tools 버전 호환성 확인 (예시)\n",
    "    print(f\"Using scvi-tools version: {scvi.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"Warning: 'scvi-tools' not found. scVI integration will not be available. Install with 'pip install scvi-tools'\")\n",
    "try:\n",
    "    import scanorama\n",
    "except ImportError:\n",
    "    print(\"Warning: 'scanorama' not found. Scanorama integration will not be available. Install with 'pip install scanorama'\")\n",
    "\n",
    "\n",
    "def integrate_anndatas(\n",
    "    adatas: List[ad.AnnData],\n",
    "    batch_key: str = \"batch\", # 각 anndata의 출처를 구분할 키\n",
    "    integration_method: Literal['harmony', 'scvi', 'scanorama'] = 'harmony',\n",
    "    # HVG 관련 파라미터 (통합 전 공통 HVG 선별 시 사용)\n",
    "    hvg_n_top_genes: Optional[int] = 2000, # None이면 HVG 선별 안 함 (각 메소드가 알아서 처리)\n",
    "    hvg_flavor: str = 'seurat_v3', # HVG 선별 시 사용될 flavor\n",
    "    # 각 메소드별 추가 파라미터 전달용\n",
    "    integration_kwargs: Optional[Dict[str, Any]] = None,\n",
    "    # scVI 특정 파라미터\n",
    "    scvi_model_kwargs: Optional[Dict[str, Any]] = None,\n",
    "    scvi_train_kwargs: Optional[Dict[str, Any]] = None,\n",
    "    scvi_adata_setup_kwargs: Optional[Dict[str, Any]] = None,\n",
    "\n",
    ") -> ad.AnnData:\n",
    "    \"\"\"\n",
    "    여러 개의 전처리된 AnnData 객체 리스트를 받아서 지정된 방법으로 통합합니다.\n",
    "\n",
    "    Args:\n",
    "        adatas: 통합할 AnnData 객체들의 리스트. 각 객체는 이미 기본적인 QC,\n",
    "                정규화 등이 수행되었다고 가정합니다. scVI는 raw count를 필요로 할 수 있습니다.\n",
    "        batch_key: 통합된 AnnData 객체에서 각 데이터셋의 출처를 나타내는 obs 키 이름.\n",
    "        integration_method: 사용할 통합 방법 ('harmony', 'scvi', 'scanorama').\n",
    "        hvg_n_top_genes: 통합 전 공통 HVG를 선별할 개수. None이면 선별하지 않고,\n",
    "                         각 통합 방법이 내부적으로 처리하도록 합니다 (scVI는 주로 내부 처리).\n",
    "                         Harmony, Scanorama는 HVG 기반으로 동작하는 것이 일반적입니다.\n",
    "        hvg_flavor: HVG 선별 시 사용할 flavor.\n",
    "        integration_kwargs: 각 통합 함수(harmony_integrate, scanorama_integrate)에\n",
    "                           전달할 추가 키워드 인자 딕셔너리.\n",
    "        scvi_model_kwargs: scVI 모델 초기화 시 전달할 인자 딕셔너리.\n",
    "        scvi_train_kwargs: scVI 모델 훈련 시 전달할 인자 딕셔너리.\n",
    "        scvi_adata_setup_kwargs: scVI 모델의 setup_anndata 메소드에 전달할 인자 딕셔너리.\n",
    "\n",
    "    Returns:\n",
    "        통합된 AnnData 객체. 통합된 임베딩은 보통 .obsm 필드에 저장됩니다\n",
    "        (e.g., 'X_pca_harmony', 'X_scVI', 'X_scanorama').\n",
    "\n",
    "    Raises:\n",
    "        ValueError: 입력 adatas 리스트가 비어 있거나, 필수 라이브러리가 설치되지 않은 경우.\n",
    "        ModuleNotFoundError: 필요한 통합 라이브러리가 설치되지 않은 경우.\n",
    "        Exception: 통합 과정 중 오류 발생 시.\n",
    "    \"\"\"\n",
    "    print(f\"--- Starting AnnData Integration ---\")\n",
    "    if not adatas:\n",
    "        raise ValueError(\"Input AnnData list is empty.\")\n",
    "    if integration_kwargs is None:\n",
    "        integration_kwargs = {}\n",
    "    if scvi_model_kwargs is None:\n",
    "        scvi_model_kwargs = {}\n",
    "    if scvi_train_kwargs is None:\n",
    "        scvi_train_kwargs = {'max_epochs': 100} # 기본값 예시\n",
    "    if scvi_adata_setup_kwargs is None:\n",
    "        scvi_adata_setup_kwargs = {}\n",
    "\n",
    "\n",
    "    print(f\"Received {len(adatas)} AnnData objects for integration using '{integration_method}'.\")\n",
    "\n",
    "    # 1. 데이터 통합 준비 (Concatenate)\n",
    "    # 각 AnnData에 batch 정보 추가 (obs에 batch_key 컬럼 생성)\n",
    "    batch_labels = []\n",
    "    adatas_processed = []\n",
    "    for i, ad_ in enumerate(adatas):\n",
    "        ad_copy = ad_.copy() # 원본 유지를 위해 복사\n",
    "        batch_label = f\"batch_{i}\"\n",
    "        ad_copy.obs[batch_key] = batch_label\n",
    "        batch_labels.append(batch_label)\n",
    "        # 모든 anndata가 동일한 유전자(var_names)를 갖도록 확인/조정 필요\n",
    "        # 간단하게는 첫 번째 anndata의 유전자를 기준으로 intersection 수행\n",
    "        if i > 0:\n",
    "             common_vars = adatas_processed[0].var_names.intersection(ad_copy.var_names)\n",
    "             if len(common_vars) < ad_copy.n_vars or len(common_vars) < adatas_processed[0].n_vars:\n",
    "                 print(f\"Warning: AnnData objects have different genes. Taking intersection.\")\n",
    "                 adatas_processed[0] = adatas_processed[0][:, common_vars].copy()\n",
    "                 ad_copy = ad_copy[:, common_vars].copy()\n",
    "        adatas_processed.append(ad_copy)\n",
    "\n",
    "    print(f\"Assigning batch labels: {batch_labels}\")\n",
    "\n",
    "    # AnnData 객체들 합치기\n",
    "    print(\"Concatenating AnnData objects...\")\n",
    "    try:\n",
    "        # anndata 버전 0.8 이상에서는 join='outer'가 기본값, 여기서는 명시적으로 inner 사용 검토\n",
    "        # 혹은 미리 유전자셋을 통일시키는 것이 더 안전함 (위에서 intersection 수행)\n",
    "        adata_concat = ad.concat(adatas_processed, batch_key=batch_key, join='inner', index_unique=None) # index 중복 시 None으로 처리\n",
    "        print(f\"Concatenated AnnData shape: {adata_concat.shape}\")\n",
    "    except Exception as e:\n",
    "         print(f\"Error during concatenation: {e}\")\n",
    "         # 만약 index 중복 오류 등이 발생하면 index_unique='-' 등으로 시도해볼 수 있음\n",
    "         raise\n",
    "\n",
    "    # 2. (선택적) 공통 Highly Variable Genes (HVG) 선별\n",
    "    # scVI는 보통 raw count를 사용하고 내부적으로 유전자를 다루므로 HVG 선별이 필수는 아님.\n",
    "    # Harmony, Scanorama는 HVG 기반으로 수행하는 것이 일반적.\n",
    "    use_hvg_subset = False\n",
    "    if hvg_n_top_genes is not None and integration_method in ['harmony', 'scanorama']:\n",
    "        print(f\"Finding top {hvg_n_top_genes} common highly variable genes using batch_key='{batch_key}'...\")\n",
    "        try:\n",
    "            # 배치 효과를 고려하여 HVG 선별\n",
    "            sc.pp.highly_variable_genes(\n",
    "                adata_concat,\n",
    "                n_top_genes=hvg_n_top_genes,\n",
    "                flavor=hvg_flavor,\n",
    "                batch_key=batch_key,\n",
    "                subset=False # subset=True 대신 아래에서 명시적으로 인덱싱\n",
    "            )\n",
    "            hvg_mask = adata_concat.var['highly_variable']\n",
    "            n_hvg = hvg_mask.sum()\n",
    "            if n_hvg > 0:\n",
    "                print(f\"Found {n_hvg} HVGs.\")\n",
    "                adata_hvg = adata_concat[:, hvg_mask].copy() # HVG 부분집합 생성\n",
    "                use_hvg_subset = True\n",
    "            else:\n",
    "                print(\"Warning: No HVGs found with the specified criteria. Integration will use all genes.\")\n",
    "                adata_hvg = adata_concat.copy() # 전체 유전자 사용\n",
    "        except Exception as e:\n",
    "            print(f\"Error finding HVGs: {e}. Integration will proceed with all genes.\")\n",
    "            adata_hvg = adata_concat.copy() # 오류 시 전체 유전자 사용\n",
    "    else:\n",
    "        print(\"Skipping explicit HVG selection for integration (using all genes or method's internal selection).\")\n",
    "        adata_hvg = adata_concat.copy() # HVG 선별 안 할 경우 전체 데이터 사용\n",
    "\n",
    "    # 3. 선택된 방법으로 통합 수행\n",
    "    try:\n",
    "        if integration_method == 'harmony':\n",
    "            print(\"Running Harmony integration...\")\n",
    "            if 'harmonypy' not in globals():\n",
    "                 raise ModuleNotFoundError(\"Harmony requires 'harmonypy'. Please install it.\")\n",
    "            # Harmony는 PCA 임베딩에 대해 수행됨\n",
    "            if 'X_pca' not in adata_hvg.obsm:\n",
    "                print(\"PCA embedding not found. Running PCA on HVGs (or all genes if no HVGs)...\")\n",
    "                n_pcs_harmony = min(50, adata_hvg.n_vars - 1, adata_hvg.n_obs - 1) # 적절한 PC 개수 설정\n",
    "                if n_pcs_harmony > 0:\n",
    "                    sc.tl.pca(adata_hvg, n_comps=n_pcs_harmony)\n",
    "                else:\n",
    "                    raise ValueError(\"Cannot run PCA for Harmony (not enough features or observations).\")\n",
    "\n",
    "            # scanpy의 harmony_integrate 함수 사용\n",
    "            sc.external.pp.harmony_integrate(\n",
    "                adata_hvg,\n",
    "                key=batch_key,\n",
    "                basis='X_pca', # PCA 결과를 기반으로 Harmony 수행\n",
    "                adjusted_basis='X_pca_harmony', # 결과를 저장할 obsm 키\n",
    "                **integration_kwargs # 추가 인자 전달 (e.g., max_iter_harmony, theta)\n",
    "            )\n",
    "            print(\"Harmony integration complete. Integrated embedding saved in adata.obsm['X_pca_harmony']\")\n",
    "            # 통합된 결과를 원본 AnnData 객체에 저장 (adata_concat 사용)\n",
    "            adata_concat.obsm['X_pca_harmony'] = adata_hvg.obsm['X_pca_harmony']\n",
    "            # 필요하다면 UMAP 등 후속 분석 수행\n",
    "            # sc.pp.neighbors(adata_concat, use_rep='X_pca_harmony', n_neighbors=15)\n",
    "            # sc.tl.umap(adata_concat)\n",
    "\n",
    "\n",
    "        elif integration_method == 'scvi':\n",
    "            print(\"Running scVI integration...\")\n",
    "            if 'scvi' not in globals():\n",
    "                raise ModuleNotFoundError(\"scVI integration requires 'scvi-tools'. Please install it.\")\n",
    "\n",
    "            # scVI는 주로 raw count 데이터를 입력으로 사용함.\n",
    "            # 입력 adatas에 raw count가 .X 또는 .layers['counts'] 등에 있는지 확인 필요.\n",
    "            # 여기서는 adata_concat.X 가 raw count라고 가정. 만약 다른 layer에 있다면 설정 필요.\n",
    "            # scVI 모델 설정 및 훈련\n",
    "            # setup_anndata는 inplace=True가 기본값\n",
    "            layer_key = scvi_adata_setup_kwargs.pop('layer', None) # layer 인자 추출\n",
    "            scvi.model.SCVI.setup_anndata(\n",
    "                adata_concat,\n",
    "                batch_key=batch_key,\n",
    "                layer=layer_key, # raw count가 있는 레이어 지정 (None이면 .X 사용)\n",
    "                 **scvi_adata_setup_kwargs # 다른 setup 인자 (categorical_covariate_keys 등)\n",
    "            )\n",
    "\n",
    "            # 모델 생성\n",
    "            # n_latent 등 주요 파라미터 설정 가능\n",
    "            model = scvi.model.SCVI(adata_concat, **scvi_model_kwargs)\n",
    "\n",
    "            # 모델 훈련\n",
    "            print(\"Training scVI model...\")\n",
    "            model.train(**scvi_train_kwargs) # max_epochs, use_gpu 등 설정 가능\n",
    "            print(\"scVI training complete.\")\n",
    "\n",
    "            # Latent representation 얻기\n",
    "            adata_concat.obsm['X_scVI'] = model.get_latent_representation()\n",
    "            print(\"scVI integration complete. Integrated embedding saved in adata.obsm['X_scVI']\")\n",
    "            # 필요하다면 UMAP 등 후속 분석 수행\n",
    "            # sc.pp.neighbors(adata_concat, use_rep='X_scVI', n_neighbors=15)\n",
    "            # sc.tl.umap(adata_concat)\n",
    "\n",
    "\n",
    "        elif integration_method == 'scanorama':\n",
    "            print(\"Running Scanorama integration...\")\n",
    "            if 'scanorama' not in globals():\n",
    "                raise ModuleNotFoundError(\"Scanorama requires 'scanorama'. Please install it.\")\n",
    "\n",
    "            # Scanorama는 일반적으로 log-normalized 데이터를 사용하고 HVG 기반으로 작동\n",
    "            # scanpy의 scanorama_integrate 함수 사용\n",
    "            # 입력으로 사용할 데이터 (adata_hvg 사용)\n",
    "            sc.external.pp.scanorama_integrate(\n",
    "                adata_hvg, # HVG 부분집합 또는 전체 데이터\n",
    "                key=batch_key,\n",
    "                basis='X_pca', # Scanorama는 내부적으로 PCA와 유사한 작업 수행 가능, 명시적 PCA 사용 가능\n",
    "                adjusted_basis='X_scanorama', # 결과 저장 키\n",
    "                 **integration_kwargs # 추가 인자 전달 (e.g., knn, approx)\n",
    "            )\n",
    "            print(\"Scanorama integration complete. Integrated embedding saved in adata.obsm['X_scanorama']\")\n",
    "            # 통합된 결과를 원본 AnnData 객체에 저장 (adata_concat 사용)\n",
    "            adata_concat.obsm['X_scanorama'] = adata_hvg.obsm['X_scanorama']\n",
    "            # 필요하다면 UMAP 등 후속 분석 수행\n",
    "            # sc.pp.neighbors(adata_concat, use_rep='X_scanorama', n_neighbors=15)\n",
    "            # sc.tl.umap(adata_concat)\n",
    "\n",
    "        else:\n",
    "            print(f\"Warning: Integration method '{integration_method}' is not supported by this function.\")\n",
    "            # 통합되지 않은 concatenated AnnData 반환\n",
    "            return adata_concat\n",
    "\n",
    "        print(f\"--- AnnData Integration Complete ---\")\n",
    "        # 통합된 전체 AnnData 반환\n",
    "        return adata_concat\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during {integration_method} integration: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        raise\n",
    "\n",
    "# --- 예시 사용법 ---\n",
    "# import scanpy as sc\n",
    "# import anndata as ad\n",
    "# import numpy as np\n",
    "\n",
    "# # 가상의 데이터셋 생성 (2개 배치)\n",
    "# def create_mock_adata(n_obs, n_vars, batch_label):\n",
    "#     X = np.random.poisson(2, size=(n_obs, n_vars)).astype(float) # Raw count 형태\n",
    "#     adata = ad.AnnData(X)\n",
    "#     adata.obs_names = [f\"{batch_label}_cell_{i}\" for i in range(n_obs)]\n",
    "#     adata.var_names = [f\"gene_{j}\" for j in range(n_vars)]\n",
    "#     # 기본적인 전처리 (예시)\n",
    "#     sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "#     sc.pp.log1p(adata)\n",
    "#     sc.pp.highly_variable_genes(adata, n_top_genes=1000, flavor='seurat_v3')\n",
    "#     # scVI를 사용하려면 raw count 저장 필요\n",
    "#     adata.layers['counts'] = X.copy()\n",
    "#     return adata\n",
    "\n",
    "# adata1 = create_mock_adata(200, 2000, \"batch1\")\n",
    "# adata2 = create_mock_adata(300, 2000, \"batch2\") # 동일한 유전자 목록 가정\n",
    "\n",
    "# # 통합 실행 (Harmony 예시)\n",
    "# try:\n",
    "#     integrated_adata_harmony = integrate_anndatas(\n",
    "#         adatas=[adata1, adata2],\n",
    "#         batch_key=\"sample_batch\",\n",
    "#         integration_method='harmony',\n",
    "#         hvg_n_top_genes=1500 # 공통 HVG 1500개 사용\n",
    "#     )\n",
    "#     print(\"\\nHarmony Integrated AnnData info:\")\n",
    "#     print(integrated_adata_harmony)\n",
    "#     if 'X_pca_harmony' in integrated_adata_harmony.obsm:\n",
    "#         print(f\"Harmony embedding shape: {integrated_adata_harmony.obsm['X_pca_harmony'].shape}\")\n",
    "\n",
    "# except Exception as e:\n",
    "#      print(f\"Harmony integration failed: {e}\")\n",
    "\n",
    "\n",
    "# # 통합 실행 (scVI 예시)\n",
    "# try:\n",
    "#     # scVI는 raw count 필요, layers['counts'] 사용하도록 지정\n",
    "#     integrated_adata_scvi = integrate_anndatas(\n",
    "#         adatas=[adata1, adata2],\n",
    "#         batch_key=\"sample_batch\",\n",
    "#         integration_method='scvi',\n",
    "#         hvg_n_top_genes=None, # scVI는 내부적으로 처리하므로 None 또는 생략\n",
    "#         scvi_adata_setup_kwargs={'layer': 'counts'}, # raw count가 있는 레이어 지정\n",
    "#         scvi_train_kwargs={'max_epochs': 5} # 예시로 작은 epoch 사용\n",
    "#     )\n",
    "#     print(\"\\nscVI Integrated AnnData info:\")\n",
    "#     print(integrated_adata_scvi)\n",
    "#     if 'X_scVI' in integrated_adata_scvi.obsm:\n",
    "#         print(f\"scVI embedding shape: {integrated_adata_scvi.obsm['X_scVI'].shape}\")\n",
    "\n",
    "# except Exception as e:\n",
    "#      print(f\"scVI integration failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c58104-3db0-48c6-a4a4-832eceff4a6b",
   "metadata": {},
   "source": [
    "## batch_key changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb221b79-bf5d-4998-9ad1-6e35c6c71d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "from typing import List, Literal, Optional, Dict, Any\n",
    "import os\n",
    "\n",
    "# 필요한 외부 라이브러리 import 시도 (오류 발생 시 사용자에게 설치 안내)\n",
    "try:\n",
    "    import harmonypy\n",
    "except ImportError:\n",
    "    print(\"Warning: 'harmonypy' not found. Harmony integration will not be available. Install with 'pip install harmonypy'\")\n",
    "try:\n",
    "    import scvi\n",
    "    # scvi-tools 버전 호환성 확인 (예시)\n",
    "    print(f\"Using scvi-tools version: {scvi.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"Warning: 'scvi-tools' not found. scVI integration will not be available. Install with 'pip install scvi-tools'\")\n",
    "try:\n",
    "    import scanorama\n",
    "except ImportError:\n",
    "    print(\"Warning: 'scanorama' not found. Scanorama integration will not be available. Install with 'pip install scanorama'\")\n",
    "\n",
    "\n",
    "def integrate_anndatas(\n",
    "    adatas: List[ad.AnnData],\n",
    "    batch_key: str = \"batch\", # 각 anndata의 출처를 구분할 키\n",
    "    integration_method: Literal['harmony', 'scvi', 'scanorama'] = 'harmony',\n",
    "    # HVG 관련 파라미터 (통합 전 공통 HVG 선별 시 사용)\n",
    "    hvg_n_top_genes: Optional[int] = 2000, # None이면 HVG 선별 안 함 (각 메소드가 알아서 처리)\n",
    "    hvg_flavor: str = 'seurat_v3', # HVG 선별 시 사용될 flavor\n",
    "    # 각 메소드별 추가 파라미터 전달용\n",
    "    integration_kwargs: Optional[Dict[str, Any]] = None,\n",
    "    # scVI 특정 파라미터\n",
    "    scvi_model_kwargs: Optional[Dict[str, Any]] = None,\n",
    "    scvi_train_kwargs: Optional[Dict[str, Any]] = None,\n",
    "    scvi_adata_setup_kwargs: Optional[Dict[str, Any]] = None,\n",
    "\n",
    ") -> ad.AnnData:\n",
    "    \"\"\"\n",
    "    여러 개의 전처리된 AnnData 객체 리스트를 받아서 지정된 방법으로 통합합니다.\n",
    "\n",
    "    Args:\n",
    "        adatas: 통합할 AnnData 객체들의 리스트. 각 객체는 이미 기본적인 QC,\n",
    "                정규화 등이 수행되었다고 가정합니다. scVI는 raw count를 필요로 할 수 있습니다.\n",
    "        batch_key: 통합된 AnnData 객체에서 각 데이터셋의 출처를 나타내는 obs 키 이름.\n",
    "        integration_method: 사용할 통합 방법 ('harmony', 'scvi', 'scanorama').\n",
    "        hvg_n_top_genes: 통합 전 공통 HVG를 선별할 개수. None이면 선별하지 않고,\n",
    "                         각 통합 방법이 내부적으로 처리하도록 합니다 (scVI는 주로 내부 처리).\n",
    "                         Harmony, Scanorama는 HVG 기반으로 동작하는 것이 일반적입니다.\n",
    "        hvg_flavor: HVG 선별 시 사용할 flavor.\n",
    "        integration_kwargs: 각 통합 함수(harmony_integrate, scanorama_integrate)에\n",
    "                           전달할 추가 키워드 인자 딕셔너리.\n",
    "        scvi_model_kwargs: scVI 모델 초기화 시 전달할 인자 딕셔너리.\n",
    "        scvi_train_kwargs: scVI 모델 훈련 시 전달할 인자 딕셔너리.\n",
    "        scvi_adata_setup_kwargs: scVI 모델의 setup_anndata 메소드에 전달할 인자 딕셔너리.\n",
    "\n",
    "    Returns:\n",
    "        통합된 AnnData 객체. 통합된 임베딩은 보통 .obsm 필드에 저장됩니다\n",
    "        (e.g., 'X_pca_harmony', 'X_scVI', 'X_scanorama').\n",
    "\n",
    "    Raises:\n",
    "        ValueError: 입력 adatas 리스트가 비어 있거나, 필수 라이브러리가 설치되지 않은 경우.\n",
    "        ModuleNotFoundError: 필요한 통합 라이브러리가 설치되지 않은 경우.\n",
    "        Exception: 통합 과정 중 오류 발생 시.\n",
    "    \"\"\"\n",
    "    print(f\"--- Starting AnnData Integration ---\")\n",
    "    if not adatas:\n",
    "        raise ValueError(\"Input AnnData list is empty.\")\n",
    "    if integration_kwargs is None:\n",
    "        integration_kwargs = {}\n",
    "    if scvi_model_kwargs is None:\n",
    "        scvi_model_kwargs = {}\n",
    "    if scvi_train_kwargs is None:\n",
    "        scvi_train_kwargs = {'max_epochs': 100} # 기본값 예시\n",
    "    if scvi_adata_setup_kwargs is None:\n",
    "        scvi_adata_setup_kwargs = {}\n",
    "\n",
    "\n",
    "    print(f\"Received {len(adatas)} AnnData objects for integration using '{integration_method}'.\")\n",
    "\n",
    "    # 1. 데이터 통합 준비 (Concatenate)\n",
    "    # 각 AnnData에 batch 정보 추가 (obs에 batch_key 컬럼 생성)\n",
    "    batch_labels = []\n",
    "    adatas_processed = []\n",
    "    for i, ad_ in enumerate(adatas):\n",
    "        ad_copy = ad_.copy() # 원본 유지를 위해 복사\n",
    "        batch_label = f\"batch_{i}\"\n",
    "        ad_copy.obs[batch_key] = batch_label\n",
    "        batch_labels.append(batch_label)\n",
    "        # 모든 anndata가 동일한 유전자(var_names)를 갖도록 확인/조정 필요\n",
    "        # 간단하게는 첫 번째 anndata의 유전자를 기준으로 intersection 수행\n",
    "        if i > 0:\n",
    "             common_vars = adatas_processed[0].var_names.intersection(ad_copy.var_names)\n",
    "             if len(common_vars) < ad_copy.n_vars or len(common_vars) < adatas_processed[0].n_vars:\n",
    "                 print(f\"Warning: AnnData objects have different genes. Taking intersection.\")\n",
    "                 adatas_processed[0] = adatas_processed[0][:, common_vars].copy()\n",
    "                 ad_copy = ad_copy[:, common_vars].copy()\n",
    "        adatas_processed.append(ad_copy)\n",
    "\n",
    "    print(f\"Assigning batch labels: {batch_labels}\")\n",
    "\n",
    "    # AnnData 객체들 합치기 (수정된 부분)\n",
    "    print(\"Concatenating AnnData objects...\")\n",
    "    try:\n",
    "        # anndata 버전 0.8 미만 호환성을 위해 batch_key 인자 제거\n",
    "        # batch 정보는 이미 adatas_processed 안의 각 anndata 객체 .obs에 추가됨\n",
    "        adata_concat = ad.concat(\n",
    "            adatas_processed,\n",
    "            join='inner',     # 유전자가 다를 경우 공통 유전자만 사용\n",
    "            index_unique=None # 필요시 obs index 이름 중복 처리 (예: '-')\n",
    "        )\n",
    "        print(f\"Concatenated AnnData shape: {adata_concat.shape}\")\n",
    "        # .obs에 batch_key가 제대로 들어갔는지 확인 (디버깅용)\n",
    "        if batch_key in adata_concat.obs.columns:\n",
    "             print(f\"Batch key '{batch_key}' found in concatenated AnnData.obs.\")\n",
    "             print(adata_concat.obs[batch_key].value_counts())\n",
    "        else:\n",
    "             print(f\"Warning: Batch key '{batch_key}' NOT found in concatenated AnnData.obs.\")\n",
    "\n",
    "    except Exception as e:\n",
    "         print(f\"Error during concatenation: {e}\")\n",
    "         # 만약 index 중복 오류 등이 발생하면 index_unique='-' 등으로 시도해볼 수 있음\n",
    "         raise\n",
    "\n",
    "    # 2. (선택적) 공통 Highly Variable Genes (HVG) 선별\n",
    "    # scVI는 보통 raw count를 사용하고 내부적으로 유전자를 다루므로 HVG 선별이 필수는 아님.\n",
    "    # Harmony, Scanorama는 HVG 기반으로 수행하는 것이 일반적.\n",
    "    use_hvg_subset = False\n",
    "    if hvg_n_top_genes is not None and integration_method in ['harmony', 'scanorama']:\n",
    "        print(f\"Finding top {hvg_n_top_genes} common highly variable genes using batch_key='{batch_key}'...\")\n",
    "        try:\n",
    "            # 배치 효과를 고려하여 HVG 선별\n",
    "            sc.pp.highly_variable_genes(\n",
    "                adata_concat,\n",
    "                n_top_genes=hvg_n_top_genes,\n",
    "                flavor=hvg_flavor,\n",
    "                batch_key=batch_key,\n",
    "                subset=False # subset=True 대신 아래에서 명시적으로 인덱싱\n",
    "            )\n",
    "            hvg_mask = adata_concat.var['highly_variable']\n",
    "            n_hvg = hvg_mask.sum()\n",
    "            if n_hvg > 0:\n",
    "                print(f\"Found {n_hvg} HVGs.\")\n",
    "                adata_hvg = adata_concat[:, hvg_mask].copy() # HVG 부분집합 생성\n",
    "                use_hvg_subset = True\n",
    "            else:\n",
    "                print(\"Warning: No HVGs found with the specified criteria. Integration will use all genes.\")\n",
    "                adata_hvg = adata_concat.copy() # 전체 유전자 사용\n",
    "        except Exception as e:\n",
    "            print(f\"Error finding HVGs: {e}. Integration will proceed with all genes.\")\n",
    "            adata_hvg = adata_concat.copy() # 오류 시 전체 유전자 사용\n",
    "    else:\n",
    "        print(\"Skipping explicit HVG selection for integration (using all genes or method's internal selection).\")\n",
    "        adata_hvg = adata_concat.copy() # HVG 선별 안 할 경우 전체 데이터 사용\n",
    "\n",
    "    # 3. 선택된 방법으로 통합 수행\n",
    "    try:\n",
    "        if integration_method == 'harmony':\n",
    "            print(\"Running Harmony integration...\")\n",
    "            if 'harmonypy' not in globals():\n",
    "                 raise ModuleNotFoundError(\"Harmony requires 'harmonypy'. Please install it.\")\n",
    "            # Harmony는 PCA 임베딩에 대해 수행됨\n",
    "            if 'X_pca' not in adata_hvg.obsm:\n",
    "                print(\"PCA embedding not found. Running PCA on HVGs (or all genes if no HVGs)...\")\n",
    "                n_pcs_harmony = min(50, adata_hvg.n_vars - 1, adata_hvg.n_obs - 1) # 적절한 PC 개수 설정\n",
    "                if n_pcs_harmony > 0:\n",
    "                    sc.tl.pca(adata_hvg, n_comps=n_pcs_harmony)\n",
    "                else:\n",
    "                    raise ValueError(\"Cannot run PCA for Harmony (not enough features or observations).\")\n",
    "\n",
    "            # scanpy의 harmony_integrate 함수 사용\n",
    "            sc.external.pp.harmony_integrate(\n",
    "                adata_hvg,\n",
    "                key=batch_key,\n",
    "                basis='X_pca', # PCA 결과를 기반으로 Harmony 수행\n",
    "                adjusted_basis='X_pca_harmony', # 결과를 저장할 obsm 키\n",
    "                **integration_kwargs # 추가 인자 전달 (e.g., max_iter_harmony, theta)\n",
    "            )\n",
    "            print(\"Harmony integration complete. Integrated embedding saved in adata.obsm['X_pca_harmony']\")\n",
    "            # 통합된 결과를 원본 AnnData 객체에 저장 (adata_concat 사용)\n",
    "            adata_concat.obsm['X_pca_harmony'] = adata_hvg.obsm['X_pca_harmony']\n",
    "            # 필요하다면 UMAP 등 후속 분석 수행\n",
    "            # sc.pp.neighbors(adata_concat, use_rep='X_pca_harmony', n_neighbors=15)\n",
    "            # sc.tl.umap(adata_concat)\n",
    "\n",
    "\n",
    "        elif integration_method == 'scvi':\n",
    "            print(\"Running scVI integration...\")\n",
    "            if 'scvi' not in globals():\n",
    "                raise ModuleNotFoundError(\"scVI integration requires 'scvi-tools'. Please install it.\")\n",
    "\n",
    "            # scVI는 주로 raw count 데이터를 입력으로 사용함.\n",
    "            # 입력 adatas에 raw count가 .X 또는 .layers['counts'] 등에 있는지 확인 필요.\n",
    "            # 여기서는 adata_concat.X 가 raw count라고 가정. 만약 다른 layer에 있다면 설정 필요.\n",
    "            # scVI 모델 설정 및 훈련\n",
    "            # setup_anndata는 inplace=True가 기본값\n",
    "            layer_key = scvi_adata_setup_kwargs.pop('layer', None) # layer 인자 추출\n",
    "            scvi.model.SCVI.setup_anndata(\n",
    "                adata_concat,\n",
    "                batch_key=batch_key,\n",
    "                layer=layer_key, # raw count가 있는 레이어 지정 (None이면 .X 사용)\n",
    "                 **scvi_adata_setup_kwargs # 다른 setup 인자 (categorical_covariate_keys 등)\n",
    "            )\n",
    "\n",
    "            # 모델 생성\n",
    "            # n_latent 등 주요 파라미터 설정 가능\n",
    "            model = scvi.model.SCVI(adata_concat, **scvi_model_kwargs)\n",
    "\n",
    "            # 모델 훈련\n",
    "            print(\"Training scVI model...\")\n",
    "            model.train(**scvi_train_kwargs) # max_epochs, use_gpu 등 설정 가능\n",
    "            print(\"scVI training complete.\")\n",
    "\n",
    "            # Latent representation 얻기\n",
    "            adata_concat.obsm['X_scVI'] = model.get_latent_representation()\n",
    "            print(\"scVI integration complete. Integrated embedding saved in adata.obsm['X_scVI']\")\n",
    "            # 필요하다면 UMAP 등 후속 분석 수행\n",
    "            # sc.pp.neighbors(adata_concat, use_rep='X_scVI', n_neighbors=15)\n",
    "            # sc.tl.umap(adata_concat)\n",
    "\n",
    "\n",
    "        elif integration_method == 'scanorama':\n",
    "            print(\"Running Scanorama integration...\")\n",
    "            if 'scanorama' not in globals():\n",
    "                raise ModuleNotFoundError(\"Scanorama requires 'scanorama'. Please install it.\")\n",
    "\n",
    "            # Scanorama는 일반적으로 log-normalized 데이터를 사용하고 HVG 기반으로 작동\n",
    "            # scanpy의 scanorama_integrate 함수 사용\n",
    "            # 입력으로 사용할 데이터 (adata_hvg 사용)\n",
    "            sc.external.pp.scanorama_integrate(\n",
    "                adata_hvg, # HVG 부분집합 또는 전체 데이터\n",
    "                key=batch_key,\n",
    "                basis='X_pca', # Scanorama는 내부적으로 PCA와 유사한 작업 수행 가능, 명시적 PCA 사용 가능\n",
    "                adjusted_basis='X_scanorama', # 결과 저장 키\n",
    "                 **integration_kwargs # 추가 인자 전달 (e.g., knn, approx)\n",
    "            )\n",
    "            print(\"Scanorama integration complete. Integrated embedding saved in adata.obsm['X_scanorama']\")\n",
    "            # 통합된 결과를 원본 AnnData 객체에 저장 (adata_concat 사용)\n",
    "            adata_concat.obsm['X_scanorama'] = adata_hvg.obsm['X_scanorama']\n",
    "            # 필요하다면 UMAP 등 후속 분석 수행\n",
    "            # sc.pp.neighbors(adata_concat, use_rep='X_scanorama', n_neighbors=15)\n",
    "            # sc.tl.umap(adata_concat)\n",
    "\n",
    "        else:\n",
    "            print(f\"Warning: Integration method '{integration_method}' is not supported by this function.\")\n",
    "            # 통합되지 않은 concatenated AnnData 반환\n",
    "            return adata_concat\n",
    "\n",
    "        print(f\"--- AnnData Integration Complete ---\")\n",
    "        # 통합된 전체 AnnData 반환\n",
    "        return adata_concat\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during {integration_method} integration: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        raise\n",
    "\n",
    "# --- 예시 사용법 ---\n",
    "# import scanpy as sc\n",
    "# import anndata as ad\n",
    "# import numpy as np\n",
    "\n",
    "# # 가상의 데이터셋 생성 (2개 배치)\n",
    "# def create_mock_adata(n_obs, n_vars, batch_label):\n",
    "#     X = np.random.poisson(2, size=(n_obs, n_vars)).astype(float) # Raw count 형태\n",
    "#     adata = ad.AnnData(X)\n",
    "#     adata.obs_names = [f\"{batch_label}_cell_{i}\" for i in range(n_obs)]\n",
    "#     adata.var_names = [f\"gene_{j}\" for j in range(n_vars)]\n",
    "#     # 기본적인 전처리 (예시)\n",
    "#     sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "#     sc.pp.log1p(adata)\n",
    "#     sc.pp.highly_variable_genes(adata, n_top_genes=1000, flavor='seurat_v3')\n",
    "#     # scVI를 사용하려면 raw count 저장 필요\n",
    "#     adata.layers['counts'] = X.copy()\n",
    "#     return adata\n",
    "\n",
    "# adata1 = create_mock_adata(200, 2000, \"batch1\")\n",
    "# adata2 = create_mock_adata(300, 2000, \"batch2\") # 동일한 유전자 목록 가정\n",
    "\n",
    "# # 통합 실행 (Harmony 예시)\n",
    "# try:\n",
    "#     integrated_adata_harmony = integrate_anndatas(\n",
    "#         adatas=[adata1, adata2],\n",
    "#         batch_key=\"sample_batch\",\n",
    "#         integration_method='harmony',\n",
    "#         hvg_n_top_genes=1500 # 공통 HVG 1500개 사용\n",
    "#     )\n",
    "#     print(\"\\nHarmony Integrated AnnData info:\")\n",
    "#     print(integrated_adata_harmony)\n",
    "#     if 'X_pca_harmony' in integrated_adata_harmony.obsm:\n",
    "#         print(f\"Harmony embedding shape: {integrated_adata_harmony.obsm['X_pca_harmony'].shape}\")\n",
    "\n",
    "# except Exception as e:\n",
    "#      print(f\"Harmony integration failed: {e}\")\n",
    "\n",
    "\n",
    "# # 통합 실행 (scVI 예시)\n",
    "# try:\n",
    "#     # scVI는 raw count 필요, layers['counts'] 사용하도록 지정\n",
    "#     integrated_adata_scvi = integrate_anndatas(\n",
    "#         adatas=[adata1, adata2],\n",
    "#         batch_key=\"sample_batch\",\n",
    "#         integration_method='scvi',\n",
    "#         hvg_n_top_genes=None, # scVI는 내부적으로 처리하므로 None 또는 생략\n",
    "#         scvi_adata_setup_kwargs={'layer': 'counts'}, # raw count가 있는 레이어 지정\n",
    "#         scvi_train_kwargs={'max_epochs': 5} # 예시로 작은 epoch 사용\n",
    "#     )\n",
    "#     print(\"\\nscVI Integrated AnnData info:\")\n",
    "#     print(integrated_adata_scvi)\n",
    "#     if 'X_scVI' in integrated_adata_scvi.obsm:\n",
    "#         print(f\"scVI embedding shape: {integrated_adata_scvi.obsm['X_scVI'].shape}\")\n",
    "\n",
    "# except Exception as e:\n",
    "#      print(f\"scVI integration failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0101c70c-f34e-4618-a403-4080dbefd023",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f30dbdff-b7ca-4891-8769-54a5447d846b",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting AnnData Preprocessing ---\n",
      "Input AnnData: AnnData object with n_obs × n_vars = 42649 × 28476\n",
      "    obs: 'dataset', 'medical_condition', 'cancer_type', 'sample_id', 'sample_type', 'tumor_source', 'replicate', 'sample_tissue', 'anatomic_region', 'anatomic_location', 'tumor_stage', 'tumor_stage_TNM', 'tumor_stage_TNM_T', 'tumor_stage_TNM_N', 'tumor_stage_TNM_M', 'tumor_size', 'tumor_dimensions', 'tumor_grade', 'histological_type', 'microsatellite_status', 'mismatch_repair_deficiency_status', 'MLH1_promoter_methylation_status', 'MLH1_status', 'KRAS_status', 'BRAF_status', 'APC_status', 'TP53_status', 'PIK3CA_status', 'SMAD4_status', 'NRAS_status', 'MSH6_status', 'FBXW7_status', 'NOTCH1_status', 'MSH2_status', 'PMS2_status', 'POLE_status', 'ERBB2_status', 'STK11_status', 'HER2_status', 'CTNNB1_status', 'BRAS_status', 'patient_id', 'sex', 'age', 'treatment_status_before_resection', 'treatment_drug', 'treatment_response', 'RECIST', 'platform', 'platform_fine', 'cellranger_version', 'reference_genome', 'matrix_type', 'enrichment_cell_types', 'tissue_cell_state', 'tissue_processing_lab', 'hospital_location', 'country', 'NCBI_BioProject_accession', 'SRA_sample_accession', 'GEO_sample_accession', 'ENA_sample_accession', 'synapse_sample_accession', 'study_id', 'study_doi', 'study_pmid', 'original_obs_names', 'cell_type_coarse_study', 'cell_type_middle_study', 'cell_type_study', 'n_counts', 'n_genes', 'n_genes_by_counts', 'total_counts', 'pct_counts_in_top_20_genes', 'pct_counts_mito', 'S_score', 'G2M_score', 'phase', 'SOLO_doublet_prob', 'SOLO_singlet_prob', 'SOLO_doublet_status', 'cell_type_predicted', 'cell_type_coarse', 'cell_type_middle', 'cell_type_fine', 'CMS_type', 'immune_infiltration_type', 'is_primary_data', 'suspension_type', 'tissue_type', 'donor_id', 'disease', 'disease_ontology_term_id', 'assay', 'assay_ontology_term_id', 'tissue', 'tissue_ontology_term_id', 'sex_ontology_term_id', 'self_reported_ethnicity', 'self_reported_ethnicity_ontology_term_id', 'organism', 'organism_ontology_term_id', 'development_stage', 'development_stage_ontology_term_id', 'cell_type', 'cell_type_ontology_term_id'\n",
      "    var: 'var_names', 'ensembl', 'Geneid', 'GeneSymbol', 'Chromosome', 'Start', 'End', 'Class', 'Strand', 'Length', 'Version', 'Dataset_25pct_Overlap', 'n_cells', 'n_counts', 'n_cells_by_counts', 'mean_counts', 'total_counts', 'highly_variable', 'original_ensembl_id_with_version', 'base_ensembl_id'\n",
      "    obsm: 'X_scANVI', 'X_scVI', 'X_umap'\n",
      "    layers: 'counts'\n",
      "Calculating QC metrics...\n",
      "Filtering cells (min_genes=50, min_counts=100)...\n",
      "Cells before filtering: 42649\n",
      "Cells after filtering: 42646\n",
      "Filtering genes (min_cells=3)...\n",
      "Genes before filtering: 28476\n",
      "Genes after filtering: 26195\n",
      "Data shape after filtering: (42646, 26195)\n",
      "Applying log-normalization (target_sum=100.0)...\n",
      "Finding highly variable genes...\n",
      "Found 290 highly variable genes.\n",
      "Scaling data...\n",
      "Running PCA...\n",
      "Calculating neighbors graph...\n",
      "Running louvain clustering (resolution=0.5)...\n",
      "Running UMAP...\n",
      "--- AnnData Preprocessing Complete ---\n",
      "Final AnnData object after preprocessing: AnnData object with n_obs × n_vars = 42646 × 26195\n",
      "    obs: 'dataset', 'medical_condition', 'cancer_type', 'sample_id', 'sample_type', 'tumor_source', 'replicate', 'sample_tissue', 'anatomic_region', 'anatomic_location', 'tumor_stage', 'tumor_stage_TNM', 'tumor_stage_TNM_T', 'tumor_stage_TNM_N', 'tumor_stage_TNM_M', 'tumor_size', 'tumor_dimensions', 'tumor_grade', 'histological_type', 'microsatellite_status', 'mismatch_repair_deficiency_status', 'MLH1_promoter_methylation_status', 'MLH1_status', 'KRAS_status', 'BRAF_status', 'APC_status', 'TP53_status', 'PIK3CA_status', 'SMAD4_status', 'NRAS_status', 'MSH6_status', 'FBXW7_status', 'NOTCH1_status', 'MSH2_status', 'PMS2_status', 'POLE_status', 'ERBB2_status', 'STK11_status', 'HER2_status', 'CTNNB1_status', 'BRAS_status', 'patient_id', 'sex', 'age', 'treatment_status_before_resection', 'treatment_drug', 'treatment_response', 'RECIST', 'platform', 'platform_fine', 'cellranger_version', 'reference_genome', 'matrix_type', 'enrichment_cell_types', 'tissue_cell_state', 'tissue_processing_lab', 'hospital_location', 'country', 'NCBI_BioProject_accession', 'SRA_sample_accession', 'GEO_sample_accession', 'ENA_sample_accession', 'synapse_sample_accession', 'study_id', 'study_doi', 'study_pmid', 'original_obs_names', 'cell_type_coarse_study', 'cell_type_middle_study', 'cell_type_study', 'n_counts', 'n_genes', 'n_genes_by_counts', 'total_counts', 'pct_counts_in_top_20_genes', 'pct_counts_mito', 'S_score', 'G2M_score', 'phase', 'SOLO_doublet_prob', 'SOLO_singlet_prob', 'SOLO_doublet_status', 'cell_type_predicted', 'cell_type_coarse', 'cell_type_middle', 'cell_type_fine', 'CMS_type', 'immune_infiltration_type', 'is_primary_data', 'suspension_type', 'tissue_type', 'donor_id', 'disease', 'disease_ontology_term_id', 'assay', 'assay_ontology_term_id', 'tissue', 'tissue_ontology_term_id', 'sex_ontology_term_id', 'self_reported_ethnicity', 'self_reported_ethnicity_ontology_term_id', 'organism', 'organism_ontology_term_id', 'development_stage', 'development_stage_ontology_term_id', 'cell_type', 'cell_type_ontology_term_id', 'louvain_res0.5'\n",
      "    var: 'var_names', 'ensembl', 'Geneid', 'GeneSymbol', 'Chromosome', 'Start', 'End', 'Class', 'Strand', 'Length', 'Version', 'Dataset_25pct_Overlap', 'n_cells', 'n_counts', 'n_cells_by_counts', 'mean_counts', 'total_counts', 'highly_variable', 'original_ensembl_id_with_version', 'base_ensembl_id', 'pct_dropout_by_counts', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'\n",
      "    uns: 'log1p', 'hvg', 'pca', 'neighbors', 'louvain_res0.5', 'umap'\n",
      "    obsm: 'X_scANVI', 'X_scVI', 'X_umap', 'X_pca'\n",
      "    varm: 'PCs'\n",
      "    layers: 'counts'\n",
      "    obsp: 'distances', 'connectivities'\n"
     ]
    }
   ],
   "source": [
    "sc_processed = preprocess_ann_data_flexible(\n",
    "    adata=sc_data,\n",
    "    output_dir='./results',\n",
    "    output_prefix='crc_100_processed',\n",
    "    min_genes=50,\n",
    "    min_counts=100,\n",
    "    min_cells=3,\n",
    "    normalization_method='log_normalize',\n",
    "    target_sum=1e2,\n",
    "    n_pcs=30,\n",
    "    n_neighbors=10,\n",
    "    clustering_method='louvain', # louvain 사용\n",
    "    cluster_resolution=0.5,\n",
    "    hvg_flavor=\"seurat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08bf075e-6c60-47c3-aa40-2488297b97e7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting AnnData Integration ---\n",
      "Received 2 AnnData objects for integration using 'scvi'.\n",
      "Warning: AnnData objects have different genes. Taking intersection.\n",
      "Assigning batch labels: ['batch_0', 'batch_1']\n",
      "Concatenating AnnData objects...\n",
      "Error during concatenation: concat() got an unexpected keyword argument 'batch_key'\n",
      "scVI integration failed: concat() got an unexpected keyword argument 'batch_key'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # scVI는 raw count 필요, layers['counts'] 사용하도록 지정\n",
    "    integrated_adata_scvi = integrate_anndatas(\n",
    "        adatas=[sc_data, st_data],\n",
    "        batch_key=\"sample_batch\",\n",
    "        integration_method='scvi',\n",
    "        hvg_n_top_genes=None, # scVI는 내부적으로 처리하므로 None 또는 생략\n",
    "        scvi_adata_setup_kwargs={'layer': 'counts'}, # raw count가 있는 레이어 지정\n",
    "        scvi_train_kwargs={'max_epochs': 5} # 예시로 작은 epoch 사용\n",
    "    )\n",
    "    print(\"\\nscVI Integrated AnnData info:\")\n",
    "    print(integrated_adata_scvi)\n",
    "    if 'X_scVI' in integrated_adata_scvi.obsm:\n",
    "        print(f\"scVI embedding shape: {integrated_adata_scvi.obsm['X_scVI'].shape}\")\n",
    "except Exception as e:\n",
    "     print(f\"scVI integration failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4adb0f6-4ccc-4524-8991-6d9fc22b94c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb5e817-1cc6-48ea-8adf-fe6e38e4de3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5be2ef9-6378-4d71-81b9-5863947ed1ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adcd3ff-ad3b-4de5-ac16-43f8054e1ba4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc85a8c-f34a-4cc0-8770-e8c052c8bdf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd8490c-c143-4d5d-a2ee-7a156db9943f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81550ff3-4983-486c-b81d-1aa6298e7895",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef1b082-4c9e-4baa-a24a-48c75080e7cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08347723-d7af-4eb7-b7dd-d911c59c4696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70810881-3303-4ac5-8d4f-7497e86ae6e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
